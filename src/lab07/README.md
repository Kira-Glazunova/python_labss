# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ7
### –ó–∞–¥–∞–Ω–∏–µ A - test_text
```python
import pytest
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append("C:/Users/kira_/OneDrive/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/python_labss/")

from src.lib.text import normalize, tokenize, count_freq, top_n


class TestNormalize:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ normalize()"""

    @pytest.mark.parametrize(
        "input_text, expected",
        [
            ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
            ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
            ("Hello\r\nWorld", "hello world"),
            ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
            ("", ""),
            ("   ", ""),
            ("–¢–µ–∫—Å—Ç\n—Å\n–ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏", "—Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏"),
            ("–†–∞–∑\t\t–¥–≤–∞\t—Ç—Ä–∏", "—Ä–∞–∑ –¥–≤–∞ —Ç—Ä–∏"),
            ("–í–µ—Ä—Ö–Ω–∏–π –†–ï–ì–ò–°–¢–†", "–≤–µ—Ä—Ö–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä"),
            ("—Å–º–µ—Å—å –Å –∏ –ï", "—Å–º–µ—Å—å –µ –∏ –µ"),
        ],
    )
    def test_normalize_basic(self, input_text, expected):
        """–ë–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏"""
        assert normalize(input_text) == expected

    def test_normalize_casefold_false(self):
        """–¢–µ—Å—Ç —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º casefold"""
        text = "–ü—Ä–ò–≤–ï—Ç –ú–∏–†"
        result = normalize(text, casefold=False)
        assert result == "–ü—Ä–ò–≤–ï—Ç –ú–∏–†"

    def test_normalize_yo2e_false(self):
        """–¢–µ—Å—Ç —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω–æ–π –∑–∞–º–µ–Ω–æ–π —ë –Ω–∞ –µ"""
        text = "—ë–∂–∏–∫ –Å–ª–∫–∞"
        result = normalize(text, yo2e=False)
        assert result == "—ë–∂–∏–∫ —ë–ª–∫–∞"


class TestTokenize:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ tokenize()"""

    @pytest.mark.parametrize(
        "input_text, expected",
        [
            ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
            ("hello,world!!!", ["hello", "world"]),
            ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
            ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
            ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
            ("", []),
            ("   ", []),
            ("!!! @#$ %^&*", []),
            ("—Å–ª–æ–≤–æ-—Å-–¥–µ—Ñ–∏—Å–æ–º –∏ –µ—â–µ", ["—Å–ª–æ–≤–æ-—Å-–¥–µ—Ñ–∏—Å–æ–º", "–∏", "–µ—â–µ"]),
            ("–º–Ω–æ–≥–æ     –ø—Ä–æ–±–µ–ª–æ–≤", ["–º–Ω–æ–≥–æ", "–ø—Ä–æ–±–µ–ª–æ–≤"]),
        ],
    )
    def test_tokenize_basic(self, input_text, expected):
        """–ë–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏"""
        assert tokenize(input_text) == expected

    def test_tokenize_with_normalized_text(self):
        """–¢–µ—Å—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏"""
        text = "–ü—Ä–ò–≤–ï—Ç, –ú–∏–†! 2025-–π –≥–æ–¥."
        normalized = normalize(text)
        tokens = tokenize(normalized)
        assert tokens == ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä", "2025", "–π", "–≥–æ–¥"]


class TestCountFreq:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ count_freq()"""

    def test_count_freq_basic(self):
        """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –ø–æ–¥—Å—á–µ—Ç–∞ —á–∞—Å—Ç–æ—Ç"""
        tokens = ["a", "b", "a", "c", "b", "a"]
        result = count_freq(tokens)
        expected = {"a": 3, "b": 2, "c": 1}
        assert result == expected

    def test_count_freq_empty(self):
        """–¢–µ—Å—Ç —Å –ø—É—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º"""
        result = count_freq([])
        assert result == {}

    def test_count_freq_single_token(self):
        """–¢–µ—Å—Ç —Å –æ–¥–Ω–∏–º —Ç–æ–∫–µ–Ω–æ–º"""
        result = count_freq(["—Å–ª–æ–≤–æ"])
        assert result == {"—Å–ª–æ–≤–æ": 1}

    def test_count_freq_case_sensitive(self):
        """–¢–µ—Å—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É"""
        tokens = ["Word", "word", "WORD"]
        result = count_freq(tokens)
        assert result == {"Word": 1, "word": 1, "WORD": 1}


class TestTopN:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ top_n()"""

    def test_top_n_basic(self):
        """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç top_n"""
        freq = {"a": 5, "b": 3, "c": 7, "d": 1, "e": 4}
        result = top_n(freq, n=3)
        expected = [("c", 7), ("a", 5), ("e", 4)]
        assert result == expected

    def test_top_n_tie_breaker(self):
        """–¢–µ—Å—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∏—á—å–∏—Ö –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É"""
        freq = {"banana": 3, "apple": 3, "cherry": 3, "date": 2}
        result = top_n(freq, n=3)
        # –ü—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —á–∞—Å—Ç–æ—Ç–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
        expected = [("apple", 3), ("banana", 3), ("cherry", 3)]
        assert result == expected

    def test_top_n_more_than_available(self):
        """–¢–µ—Å—Ç –∫–æ–≥–¥–∞ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –±–æ–ª—å—à–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ–º –µ—Å—Ç—å"""
        freq = {"a": 2, "b": 1}
        result = top_n(freq, n=10)
        assert result == [("a", 2), ("b", 1)]

    def test_top_n_empty_dict(self):
        """–¢–µ—Å—Ç —Å –ø—É—Å—Ç—ã–º —Å–ª–æ–≤–∞—Ä–µ–º"""
        result = top_n({}, n=5)
        assert result == []

    def test_top_n_n_zero(self):
        """–¢–µ—Å—Ç —Å n=0"""
        freq = {"a": 1, "b": 2}
        result = top_n(freq, n=0)
        assert result == []

    def test_top_n_negative_n(self):
        """–¢–µ—Å—Ç —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º n"""
        freq = {"a": 1, "b": 2}
        result = top_n(freq, n=-1)
        assert result == []

    @pytest.mark.parametrize(
        "n, expected",
        [
            (1, [("c", 3)]),
            (2, [("c", 3), ("a", 2)]),
            (3, [("c", 3), ("a", 2), ("b", 1)]),
        ],
    )
    def test_top_n_parametrized(self, n, expected):
        """–ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç top_n"""
        freq = {"a": 2, "b": 1, "c": 3}
        result = top_n(freq, n=n)
        assert result == expected


class TestIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –≤–º–µ—Å—Ç–µ"""

    def test_full_pipeline(self):
        """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è -> —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è -> –ø–æ–¥—Å—á–µ—Ç -> —Ç–æ–ø"""
        text = "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç –≤—Å–µ–º. –ú–∏—Ä –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω."

        normalized = normalize(text)
        assert normalized == "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä –ø—Ä–∏–≤–µ—Ç –≤—Å–µ–º –º–∏—Ä –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω"

        tokens = tokenize(normalized)
        assert tokens == ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä", "–ø—Ä–∏–≤–µ—Ç", "–≤—Å–µ–º", "–º–∏—Ä", "–ø—Ä–µ–∫—Ä–∞—Å–µ–Ω"]

        freq = count_freq(tokens)
        assert freq == {"–ø—Ä–∏–≤–µ—Ç": 2, "–º–∏—Ä": 2, "–≤—Å–µ–º": 1, "–ø—Ä–µ–∫—Ä–∞—Å–µ–Ω": 1}

        top = top_n(freq, n=2)
        # –ü—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —á–∞—Å—Ç–æ—Ç–µ "–º–∏—Ä" –∏–¥–µ—Ç –ø–µ—Ä–µ–¥ "–ø—Ä–∏–≤–µ—Ç" –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
        assert top == [("–º–∏—Ä", 2), ("–ø—Ä–∏–≤–µ—Ç", 2)]

    def test_empty_text_pipeline(self):
        """–¢–µ—Å—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –ø—É—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º"""
        text = ""

        normalized = normalize(text)
        assert normalized == ""

        tokens = tokenize(normalized)
        assert tokens == []

        freq = count_freq(tokens)
        assert freq == {}

        top = top_n(freq, n=5)
        assert top == []

```
![A](/images/lab07/1.png)

### –ó–∞–¥–∞–Ω–∏–µ B - test_json_csv
```python
import pytest
import json
import csv
import sys
from pathlib import Path
from unittest.mock import mock_open, patch

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append("C:/Users/kira_/OneDrive/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/python_labss/")

from src.lab05.json_csv import json_to_csv, csv_to_json


class TestJsonToCsv:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ json_to_csv()"""

    def test_json_to_csv_basic(self, tmp_path):
        """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ JSON -> CSV"""
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π JSON —Ñ–∞–π–ª
        json_file = tmp_path / "test.json"
        json_data = [
            {"name": "Alice", "age": 22, "city": "SPB"},
            {"name": "Bob", "age": 25, "city": "Moscow"},
            {"name": "Carlos", "age": 30, "city": "Kazan"},
        ]
        json_file.write_text(
            json.dumps(json_data, ensure_ascii=False), encoding="utf-8"
        )

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ CSV
        csv_file = tmp_path / "test.csv"
        json_to_csv(str(json_file), str(csv_file))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        assert csv_file.exists()

        with open(csv_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)

        assert len(rows) == 3
        assert set(rows[0].keys()) == {"name", "age", "city"}
        assert rows[0]["name"] == "Alice"
        assert rows[0]["age"] == "22"
        assert rows[0]["city"] == "SPB"

    def test_json_to_csv_missing_fields(self, tmp_path):
        """–¢–µ—Å—Ç —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏ –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö"""
        json_file = tmp_path / "test.json"
        json_data = [
            {"name": "Alice", "age": 22},
            {"name": "Bob", "age": 25, "city": "Moscow"},
            {"name": "Carlos", "city": "Kazan"},
        ]
        json_file.write_text(
            json.dumps(json_data, ensure_ascii=False), encoding="utf-8"
        )

        csv_file = tmp_path / "test.csv"
        json_to_csv(str(json_file), str(csv_file))

        with open(csv_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –ø–æ–ª—è –µ—Å—Ç—å –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
        assert set(rows[0].keys()) == {"name", "age", "city"}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è (–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª–µ–π)
        assert rows[0]["city"] == ""
        assert rows[2]["age"] == ""

    def test_json_to_csv_unicode(self, tmp_path):
        """–¢–µ—Å—Ç —Å Unicode —Å–∏–º–≤–æ–ª–∞–º–∏"""
        json_file = tmp_path / "test.json"
        json_data = [
            {"name": "–ê–Ω–Ω–∞", "city": "–ú–æ—Å–∫–≤–∞", "comment": "–ü—Ä–∏–≤–µ—Ç!"},
            {"name": "John", "city": "New York", "comment": "Hello!"},
        ]
        json_file.write_text(
            json.dumps(json_data, ensure_ascii=False), encoding="utf-8"
        )

        csv_file = tmp_path / "test.csv"
        json_to_csv(str(json_file), str(csv_file))

        with open(csv_file, "r", encoding="utf-8") as f:
            content = f.read()

        assert "–ê–Ω–Ω–∞" in content
        assert "–ú–æ—Å–∫–≤–∞" in content
        assert "–ü—Ä–∏–≤–µ—Ç" in content

    def test_json_to_csv_file_not_found(self):
        """–¢–µ—Å—Ç —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ñ–∞–π–ª–æ–º"""
        with pytest.raises(FileNotFoundError, match="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"):
            json_to_csv("nonexistent.json", "output.csv")

    def test_json_to_csv_invalid_json(self, tmp_path):
        """–¢–µ—Å—Ç —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON"""
        json_file = tmp_path / "test.json"
        json_file.write_text("{invalid json", encoding="utf-8")

        with pytest.raises(
            ValueError, match="–ü—É—Å—Ç–æ–π JSON –∏–ª–∏ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞"
        ):
            json_to_csv(str(json_file), "output.csv")

    def test_json_to_csv_empty_json(self, tmp_path):
        """–¢–µ—Å—Ç —Å –ø—É—Å—Ç—ã–º JSON"""
        json_file = tmp_path / "test.json"
        json_file.write_text("[]", encoding="utf-8")

        with pytest.raises(ValueError, match="–ü—É—Å—Ç–æ–π JSON"):
            json_to_csv(str(json_file), "output.csv")

    def test_json_to_csv_not_list(self, tmp_path):
        """–¢–µ—Å—Ç —Å JSON –Ω–µ —è–≤–ª—è—é—â–∏–º—Å—è —Å–ø–∏—Å–∫–æ–º"""
        json_file = tmp_path / "test.json"
        json_file.write_text('{"name": "Alice"}', encoding="utf-8")

        with pytest.raises(ValueError, match="–Ω–µ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π"):
            json_to_csv(str(json_file), "output.csv")

    def test_json_to_csv_not_list_of_dicts(self, tmp_path):
        """–¢–µ—Å—Ç —Å JSON —Å–ø–∏—Å–∫–æ–º –Ω–µ —Å–ª–æ–≤–∞—Ä–µ–π"""
        json_file = tmp_path / "test.json"
        json_file.write_text('["Alice", "Bob"]', encoding="utf-8")

        with pytest.raises(ValueError, match="–≤ —Å–ø–∏—Å–∫–µ –Ω–µ —Å–ª–æ–≤–∞—Ä–∏"):
            json_to_csv(str(json_file), "output.csv")


class TestCsvToJson:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ csv_to_json()"""

    def test_csv_to_json_basic(self, tmp_path):
        """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV -> JSON"""
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π CSV —Ñ–∞–π–ª
        csv_file = tmp_path / "test.csv"
        csv_content = """name,age,city
Alice,22,SPB
Bob,25,Moscow
Carlos,30,Kazan"""
        csv_file.write_text(csv_content, encoding="utf-8")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON
        json_file = tmp_path / "test.json"
        csv_to_json(str(csv_file), str(json_file))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        assert json_file.exists()

        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        assert len(data) == 3
        assert isinstance(data, list)
        assert all(isinstance(item, dict) for item in data)

        assert data[0] == {"name": "Alice", "age": "22", "city": "SPB"}
        assert data[1] == {"name": "Bob", "age": "25", "city": "Moscow"}
        assert data[2] == {"name": "Carlos", "age": "30", "city": "Kazan"}

    def test_csv_to_json_quotes_and_commas(self, tmp_path):
        """–¢–µ—Å—Ç —Å –∫–∞–≤—ã—á–∫–∞–º–∏ –∏ –∑–∞–ø—è—Ç—ã–º–∏ –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö"""
        csv_file = tmp_path / "test.csv"
        csv_content = '''name,message
Alice,"Hello, world!"
Bob,"He said ""wow"" and left"'''
        csv_file.write_text(csv_content, encoding="utf-8")

        json_file = tmp_path / "test.json"
        csv_to_json(str(csv_file), str(json_file))

        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        assert data[0]["message"] == "Hello, world!"
        assert data[1]["message"] == 'He said "wow" and left'

    def test_csv_to_json_unicode(self, tmp_path):
        """–¢–µ—Å—Ç —Å Unicode —Å–∏–º–≤–æ–ª–∞–º–∏"""
        csv_file = tmp_path / "test.csv"
        csv_content = """name,city
–ê–Ω–Ω–∞,–ú–æ—Å–∫–≤–∞
John,New York"""
        csv_file.write_text(csv_content, encoding="utf-8")

        json_file = tmp_path / "test.json"
        csv_to_json(str(csv_file), str(json_file))

        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        assert data[0]["name"] == "–ê–Ω–Ω–∞"
        assert data[0]["city"] == "–ú–æ—Å–∫–≤–∞"

    def test_csv_to_json_empty_csv(self, tmp_path):
        """–¢–µ—Å—Ç —Å –ø—É—Å—Ç—ã–º CSV (—Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏)"""
        csv_file = tmp_path / "test.csv"
        csv_content = "name,age,city"
        csv_file.write_text(csv_content, encoding="utf-8")

        json_file = tmp_path / "test.json"
        csv_to_json(str(csv_file), str(json_file))

        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        assert data == []

    def test_csv_to_json_missing_file(self):
        """–¢–µ—Å—Ç —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º CSV —Ñ–∞–π–ª–æ–º"""
        with pytest.raises(FileNotFoundError):
            csv_to_json("nonexistent.csv", "output.json")

    def test_csv_to_json_wrong_extension(self):
        """–¢–µ—Å—Ç —Å —Ñ–∞–π–ª–æ–º –Ω–µ–≤–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è"""
        with pytest.raises(ValueError, match="–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞"):
            csv_to_json("data.txt", "output.json")

    def test_csv_to_json_empty_file(self, tmp_path):
        """–¢–µ—Å—Ç —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–º —Ñ–∞–π–ª–æ–º"""
        csv_file = tmp_path / "test.csv"
        csv_file.write_text("", encoding="utf-8")

        with pytest.raises(ValueError, match="–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª"):
            csv_to_json(str(csv_file), "output.json")


class TestRoundTrip:
    """–¢–µ—Å—Ç—ã —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (—Ç—É–¥–∞-–æ–±—Ä–∞—Ç–Ω–æ)"""

    def test_json_csv_json_roundtrip(self, tmp_path):
        """JSON -> CSV -> JSON –¥–æ–ª–∂–µ–Ω —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ"""
        # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        original_data = [
            {"name": "Alice", "age": 22, "city": "SPB"},
            {"name": "Bob", "age": 25, "city": "Moscow"},
            {"name": "Carlos", "age": 30, "city": "Kazan", "extra": "field"},
        ]

        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        json1 = tmp_path / "test1.json"
        json1.write_text(
            json.dumps(original_data, ensure_ascii=False), encoding="utf-8"
        )

        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º JSON -> CSV
        csv_file = tmp_path / "test.csv"
        json_to_csv(str(json1), str(csv_file))

        # 3. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º CSV -> JSON
        json2 = tmp_path / "test2.json"
        csv_to_json(str(csv_file), str(json2))

        # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
        with open(json2, "r", encoding="utf-8") as f:
            roundtrip_data = json.load(f)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        assert len(roundtrip_data) == len(original_data)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
        for orig, rt in zip(original_data, roundtrip_data):
            for key in orig:
                assert key in rt
                # CSV —Ö—Ä–∞–Ω–∏—Ç –≤—Å–µ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏, –ø–æ—ç—Ç–æ–º—É —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
                assert str(orig[key]) == rt[key]

    def test_csv_json_csv_roundtrip(self, tmp_path):
        """CSV -> JSON -> CSV –¥–æ–ª–∂–µ–Ω —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ"""
        # –ò—Å—Ö–æ–¥–Ω—ã–π CSV
        csv1 = tmp_path / "test1.csv"
        csv_content = """name,age,city
Alice,22,SPB
Bob,25,Moscow
Carlos,30,Kazan"""
        csv1.write_text(csv_content, encoding="utf-8")

        # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º CSV -> JSON
        json_file = tmp_path / "test.json"
        csv_to_json(str(csv1), str(json_file))

        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º JSON -> CSV
        csv2 = tmp_path / "test2.csv"
        json_to_csv(str(json_file), str(csv2))

        # 3. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º CSV —Ñ–∞–π–ª—ã
        with open(csv1, "r", encoding="utf-8") as f1, open(
            csv2, "r", encoding="utf-8"
        ) as f2:
            content1 = f1.read()
            content2 = f2.read()

        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–æ—Ä—è–¥–∫–µ —Å—Ç—Ä–æ–∫
        lines1 = sorted(content1.splitlines())
        lines2 = sorted(content2.splitlines())

        assert lines1 == lines2

```
![B](/images/lab07/2.png)

### –ó–∞–¥–∞–Ω–∏–µ C - black
![C](/images/lab07/3.png)